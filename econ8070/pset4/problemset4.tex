% SampleProject.tex -- main LaTeX file for sample LaTeX article
%
%\documentclass[12pt]{article}
\documentclass[11pt]{SelfArxOneColBMN}
% add the pgf and tikz support.  This automatically loads
% xcolor so no need to load color
\usepackage{pgf}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usetikzlibrary{calc}
\usepackage{xstring}
\usepackage{pbox}
\usepackage{etoolbox}
\usepackage{marginfix}
\usepackage{xparse}
\usepackage{lscape}
\setlength{\parskip}{0pt}% fix as marginfix inserts a 1pt ghost parskip
% standard graphics support
\usepackage{graphicx,xcolor}
\usepackage{wrapfig}
%
\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings
%----------------------------------------------------------------------------------------
%	HYPERLINKS
%----------------------------------------------------------------------------------------
\usepackage[pdftex]{hyperref} % Required for hyperlinks
\hypersetup{hidelinks,
colorlinks,
breaklinks=true,%
urlcolor=color2,%
citecolor=color1,%
linkcolor=color1,%
bookmarksopen=false%
,pdftitle={ProblemSet 4},%
pdfauthor={Davis}}
%\usepackage[round,numbers]{natbib}
\usepackage[numbers]{natbib}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{xspace}
%
\usepackage{subfigure}
\newcommand{\goodgap}{
  \hspace{\subfigtopskip}
  \hspace{\subfigbottomskip}}
%
\usepackage{atbegshi}
%
\usepackage[hyper]{listings}
%
% use ams math packages
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{mathrsfs}
%
% use new improved Verbatim
\usepackage{fancyvrb}
%
\usepackage[titletoc,title]{appendix}
%
\usepackage{url}
%
% Create length for the baselineskip of text in footnotesize
\newdimen\footnotesizebaselineskip
\newcommand{\test}[1]{%
 \setbox0=\vbox{\footnotesize\strut Test \strut}
 \global\footnotesizebaselineskip=\ht0 \global\advance\footnotesizebaselineskip by \dp0
}
%
\usepackage{listings}

\DeclareGraphicsExtensions{.pdf, .jpg, .tif,.png}

% make sure we don't get orphaned words if at top of page
% or orphans if at bottom of page
\clubpenalty=9999
\widowpenalty=9999
\renewcommand{\textfraction}{0.15}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\floatpagefraction}{0.66}
%
\DeclareMathOperator{\sech}{sech}

\input{setupsample}

\JournalInfo{Econonomics 8070: Problem Set 4, 1-\pageref{LastPage}, 2020} % Journal information
\Archive{Draft Version \today} % Additional notes (e.g. copyright, DOI, review/research article)

\PaperTitle{Econonomics 8070: Problem Set 4}
\Authors{Ian Davis\textsuperscript{1}}
\affiliation{\textsuperscript{1}\textit{John E. Walker Department of Economics,
Clemson University,Clemson, SC: email ijdavis@g.clemson.edu}}
 % Corresponding author

\date{\small{Version ~\today}}
\Abstract{Questions from Problem Set}
\Keywords{FGLS, Fixed Effects, Random Effects}
\newcommand{\keywordname}{Keywords}
%
\onehalfspacing
\begin{document}

\flushbottom

\addcontentsline{toc}{section}{Title}
\maketitle

\begin{enumerate}
  \item Use the dataset provided, answer the following questions
  \begin{enumerate}[label=(\alph*)]
    \item Provide a table of summary statistics. That should include the mean, standard deviation, minimum, and maximum.\\
    \textbf{Answer: }See table 1 on back.
    \item Regress earnings on education, gender, ability, region, experience, and $\text{experience}^2$. Describe the results. What do the results tell you about the return to education, experience, and how ability, age, region, and gender affect earnings?\\
    \textbf{Answer: }From column 1 of table 2 we see that education, ability, and experience all are positively and significantly correlated with earnings while experience squared is negatively correlated with earnings and still significant. Being female and living in any region compared to region 1 all have no significant effect on earnings. Finally, the model has an $r^2$ of .220.
    \item Rerun the regression in part (b) without ability and compare the results. Which regression results give you a better estimate of return to education? Explain.\\
    \textbf{Answer: }From table 2 column 2, removing ability increases the coefficient attached to education by a great deal and lowers the $r^2$ without changing much else other than increasing the returns to experience. While this does increase education positive correlation with earnings, we cannot say that it is a better estimate because not everyone with $x$ years of schooling can be considered equal which is why it is important to include ability and experience.
    \item Rerun the regression in part (b) with occupation and compare the results. Which regression result gives you a better estimate of return to education? Explain.\\
    \textbf{Answer: }From table 2 column 3, we see that including occupation raises the coefficient attached to education and (although suppressed from the model) it can be noted that all but five of the occupations had a significant affect on wages when compared to the base occupation. Finally, it should be noted that the $r^2$ is up to 0.899 as opposed to 0.22 so the predictive capabilities of our model has increased a great deal. At the same time, we know that there is a high probability that education is affecting earnings through occupation so, because our goal is to find the pure effect of education on earnings, we should not include occupation in our regression. 
    \item Rerun the regression in part (b) without $\text{experience}^2$ and compare the results. Which regresion result gives you a better estimate of return to education? Explain.\\
    \textbf{Answer: }From table 2 column 4, we see that removing $experience^2$ decreases the coefficients attached to all of our significant variables which tells us that not including the returns to the returns of experience could lead us to underestimate the returns to education.
    \item Rerun the regression in part (b) with $\text{experience}^3$ and $\text{experience}^4$. Compare the results. Which regression result gives you a better estimate of return to experience? Explain.\\
    \textbf{Answer: }From table 2 column 5 We see that neither $\text{experience}^3$ nor $\text{experience}^4$ are significantly different than zero so we know that, by FWL, not including them in our regression won't change the other coefficients and will free up two degrees of freedom. Hence, regresion (b) is better.
    \item Rerun the regressionin part (b) with $\text{experience}^2$. Compare the results. Which regression gives you a better estimate of return to education.\\
    \textbf{Answer: }Both regressions are the same.
    \item Randomly pick 2000 observations from the dataset. Rerun the regression in part (b). Which regression gives you a better estmate? Explain.
    \textbf{Answer: }Because randomly chose 2000 observatios, the model to not provide much different estimates and is not any better than what we had originally.
    \item Rerun the regression in part (b) with clustered standard errors. Pick the cluster level and variable and explain your choice. Does it give you a better estimate?\\
    \textbf{Answer: }Clustering at the regional level adds significance at for varying regions but lowers the significant of our other variables. Becuase we are wanting to look at the returns to education and not geographic regions, the original regression is better.
    \item Rerun the regression in part (b) for different regions. Compare these results with the results in part (b). What extra insights can you get from these subsample regressions?\\
    \textbf{Answer: }From table 3 we are able to see how being in each region effects the coefficients attached to our variables. We wee that the return to education varies across regions which is noteworthy but does not help us derive the pure effect of education other than suggesting we may want to add an interaction term with education and region in the regression in part b.
    \item Rerun the regression in part (b) for only male or femal observations. Compare with the result with that of part (b). What extra insights can you get from these subsample regressions?\\
    \textbf{Answer: }From table 4, we see that there is a pretty significance difference between each gender's return to education. This tells us it would be worth adding an interaction term between female and education in order to control for the variability between genders. 
    \item Copy the dataset 5 times and combine them into one dataset (so you have one dataset with 50000 rows). Rerun the regression in part (b). Compare with the result in part (b), which regression gives you better estimates? Explain.\\
    \textbf{Answer: }From table 1 column 9, we see that, because we simply copied the observations, our coefficients are all the same expect a few of them have greater significance. This is not a good estimate however because we cannot extrapolate what a sample of the population would look like from a smaller sample of the population. This is why when bootstrapping you cannot draw more than your original sample size. 
  \end{enumerate}
  \item Read the following stories and explain whether Tom and Yujie are correct or not (Either Tom or Yujie can be correct, or they both can be correct, or they both can be wrong. Please explain your answer.)
  \begin{enumerate}
    \item Yujie runs a FGLS because she is concerned about heteroskadasticity. Tom agrees with her and says that estimation of FGLS is always better than those from OLS.\\
    \textbf{Answer: }Yujie is correct to run FGLS to combat heteroskadasticity but FGLS is not always B.L.U.E. so Tom is wrong to state that it is always better than OLS which is B.L.U.E
    \item Consider the model $Y = X\beta + \epsilon$ and all OLS assumptions satisfied, and we know that the OLS estimator is an unbiased estimator of $\beta$. Tom says that the IV estimator is biased if the IV $Z$ is correlated with $\epsilon$. Yujie says that the IV estimator is biased even when the exogeneity assumption is satisfied.\\
    \textbf{Answer: }Yujie is correct because the IV estimator is always biased and Tom is wrong because the correlation with $\epsilon$ is not what is causing the bias.
    \item Yujie says that fixed effects model is better than random effects because it requires weaker assumptions. Tom says that the random effects model is better because individual specific effects are random variables.
    \textbf{Answer: }Tom and Yujie are both wrong because their statements are too broad. Fixed effects can be better than random effects in certain contexts and not all individual specific effects are random as well.
    \item Yujie has a panel dataset with 10 years and 1000 individuals. her estimation involves both individual fixed effects and year fixed effects. Tom says that this is not going to work because we can include either one of those effects.
    \textbf{Answer: }Yujie is correct because, although it may not be wise, we can still add both effects. Tom is wrong because, although we can add either one, it will not be the same as controlling for both types of effects. 
    \item Using a dataset with 5 years, Yujie runs a regression with both year fixed effects and month fixed effects. Yujie says that we should include 15 dummy variables for the fixed effects, Tom says there should be 59 dummy variables.
    \textbf{Answer: }Both are incorrect.  We only need dummys for each month (12) and each year (5) which is 17 variables.
    \item Yujie estimates a fixed effect model and included gender as a covariate. Tom says that this won't work because gender is a time-invariant covariate. Yujie says it works because in the dataset one of the observations shows that the individuals changed gender once.
    \textbf{Answer: }Tom may be right depending on the size of the dataset. If it is so big that the one observation that switched gender is statistically meaningless, then gender can still be treated as time invariant.
  \end{enumerate}
\end{enumerate}

\newpage
\begin{table*}
  \centering
  \caption{Variables Summary}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    Variable & Mean & Standard Deviation & Minimum & Maximum\\
    \hline
    id & 5000.5 & 2886.896 & 1 & 10000\\
    earnings & 3772.207 & 913.7181 & 1346.25 & 3693.75\\
    occupation & 26.12.2 & 14.45669 & 0 & 52\\
    ability & 59.8287 & 23.07362 & 20 & 99\\
    age & 39.5683 & 5.761064 & 30 & 49\\
    region & 2.4933 & 1.122266 & 1 & 4\\
    female & .4994 & .5000246 & 0 & 1\\
    education & 7.8112 & 3.56878 & 2 & 17\\
    experience & 27.7538 & 7.093308 & 6 & 46\\
    \hline
  \end{tabular}
  \label{tab:1}
\end{table*}

\begin{landscape}
\input{bigRegressions.tex}
\end{landscape}
\input{regionRegressions.tex}
\input{genderRegressions.tex}
\end{document}